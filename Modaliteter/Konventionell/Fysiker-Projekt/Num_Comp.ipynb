{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date : 2024-12-13\n",
    "Author : Philip Beckman\n",
    "\n",
    "Code is part of project work to evaluate reject rate on diagnostic radiography imagery.\n",
    "Work scheduled over 2.5 weeks, and part of authors clinical intership.\n",
    "\n",
    "The code loads provided series and study data provided from Dicom-Port. It then estimates the total reject-rate per examination and per exoposure, returned as intergers and loaded back into the main dataframe, \"joined_data\".\n",
    "Finally it estimates the reject-rate for each type of examination, returned as \"duplicate_studies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Initiate system\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd \n",
    "\n",
    "# Load data as pickle\n",
    "df_Series = pd.read_pickle(\"./Data_24-12-05/series_data.pkl\")\n",
    "df_Study = pd.read_pickle(\"./Data_24-12-05/study_data.pkl\")\n",
    "\n",
    "# Merge data based on studyInstanceUID\n",
    "data = pd.merge(df_Series.reset_index(), df_Study.reset_index(), on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "# Filter merged data, remove all relatively un-wanted acq_prots\n",
    "seperate_acq_prots = ['Position Skellefteå','-----','---Frigör systemet---','.OL Benlängd 20-40kg belastad','.OL Benlängd belastad','.OL Benvinkel DX 20-40kg belastad', '.OL Benvinkel DX 20-50kg belastad',\n",
    "                                                '.OL Benvinkel DX belastad','.OL Benvinkel DX stående','.OL Benvinkel SIN 20-50kg belastad','.OL Benvinkel SIN belastad',\n",
    "                                                '.OL Benvinkel SIN stående','.OL Helrygg frontal AP 0-20kg','.OL Helrygg frontal AP 20-50kg','.OL Helrygg frontal AP vuxen','.OL Helrygg frontal PA 0-20kg',\n",
    "                                                '.OL Helrygg frontal PA 20-50kg','.OL Helrygg frontal PA vuxen','.OL Helrygg sida 0-20kg','.OL Helrygg sida 20-50kg','.OL Helrygg sida stag 20-50kg',\n",
    "                                                '.OL Helrygg sida vuxen','.OL Underben DX frontal belastad','.OL Underben SIN frontal belastad','.OL Underben SIN sida belastad','.OT Helrygg frontal',\n",
    "                                                '.OT Helrygg frontal 20-50kg','.OT Helrygg frontal vuxen','.OT Lårben DX frontal','.OT Lårben SIN frontal','.OT Tunntarmspassage','.OT Underben DX frontal',\n",
    "                                                '.OT Underben DX sida','.OT Underben SIN frontal','.OT Underben SIN sida','CP_Shunt','CP_Vuxen esofagus','CP_antiiso','OL Benvinkel DX stående',\n",
    "                                                'OL Benvinkel SIN stående','OL Helrygg frontal PA vuxen','OL Helrygg sida vuxen','OT Buköversikt','OT Helrygg frontal vuxen','OT Helrygg sida vuxen',\n",
    "                                                'OT Lårben DX frontal','OT Lårben SIN frontal','OT Tunntarm','OT Tunntarmpassage','OT Underben DX frontal','OT Underben DX sida','OT Underben SIN frontal',\n",
    "                                                'OT Underben SIN sida','OW Benlängd belastad','OW Benvinkel DX','OW Benvinkel DX 20-40 kg','OW Benvinkel SIN',\"OW Helrygg frontal 20 -30 kg\", \n",
    "                                                \"OW Helrygg frontal 30-40 kg\", \"OW Helrygg frontal 40-50 kg\", \"OW Helrygg frontal 50-60 kg\", \"OW Helrygg frontal 60-70 kg\", \"OW Helrygg frontal vuxen\", \n",
    "                                                \"OW Helrygg sida 20-30 kg\", \"OW Helrygg sida 30-40 kg\", \"OW Helrygg sida 40-50 kg\", \"OW Helrygg sida 50-60 kg\", \"OW Helrygg sida 60-70 kg\", \n",
    "                                                \"OW Helrygg sida vuxen\", \"OW Skalle-halsrygg-bröstrygg frontal\", \"OW Skalle-halsrygg-bröstrygg sida\",'Sondläge','____________________']\n",
    "filtered_data = data[~data[\"acquisitionProtocol\"].isin(seperate_acq_prots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Match data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Match and identify duplicate acq_prot per studyInstanceUID, \n",
    "duplicate_acqprot = filtered_data.pivot_table(\n",
    "    index='studyInstanceUID',\n",
    "    values='acquisitionProtocol',\n",
    "    aggfunc=[\n",
    "        lambda x: x.duplicated().sum(),\n",
    "        'count'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "duplicate_acqprot.columns = ['duplicates', 'total_count']\n",
    "\n",
    "# Calc ratio of duplicate examinations per studyInstanceUID, \n",
    "duplicate_acqprot[\"Ratio\"] = round(100*(duplicate_acqprot['duplicates'] / duplicate_acqprot['total_count']))\n",
    "\n",
    "# Add duplicate acq_prot per studyInstanceUID to main DataFrame\n",
    "joined_data = pd.merge(filtered_data, duplicate_acqprot, on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "# Remove studyInstanceUID duplicates to avoid double counting total_count when calc certain ratio\n",
    "limited_data = joined_data.drop_duplicates(\"studyInstanceUID\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 33 % of all examinations have one or more retake images\n",
      "About 16 % of all exposures are retakes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Estimate ratios of interest from dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ratio, examinations that include one or more re-takes,\n",
    "P_exam = round(100*(duplicate_acqprot['duplicates'] >0 ).sum()/len(duplicate_acqprot))\n",
    "print(f\"About {P_exam} % of all examinations have one or more retake images\")\n",
    "\n",
    "# Ratio, tot exposures due to re-takes,\n",
    "P_expo = round(100*(duplicate_acqprot['duplicates'].sum()/duplicate_acqprot['total_count'].sum()))\n",
    "print(f\"About {P_expo} % of all exposures are retakes\")\n",
    "\n",
    "# Ratio, Retakes per studyDescription\n",
    "duplicate_studies = limited_data.groupby('studyDescription').agg(\n",
    "    duplicate_count = (\"duplicates\", \"sum\",),\n",
    "    study_expo_count = (\"total_count\", \"sum\"))\n",
    "duplicate_studies[\"ratio\"] = round(100*(duplicate_studies.duplicate_count / duplicate_studies.study_expo_count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
