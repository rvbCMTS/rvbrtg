{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate system\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd \n",
    "\n",
    "# Load data as pickle\n",
    "df_Series = pd.read_pickle(r\"C:\\Users\\beckm\\Documents\\GitHub\\rvbrtg\\Modaliteter\\Konventionell\\Fysiker-Projekt\\Data_24-12-05\\series_data.pkl\")\n",
    "df_Study = pd.read_pickle(r\"C:\\Users\\beckm\\Documents\\GitHub\\rvbrtg\\Modaliteter\\Konventionell\\Fysiker-Projekt\\Data_24-12-05\\study_data.pkl\")\n",
    "\n",
    "# Merge data based on studyInstanceUID\n",
    "merged = pd.merge(df_Series.reset_index(), df_Study.reset_index(), on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "# Filter merged data, remove all non-relevant protocols,\n",
    "    # I've hard-coded this filtration based on all unique protocols.. It's not pretty but works and provides a list of all protocols to calc separately (later)\n",
    "ft_merged = merged[~merged[\"acquisitionProtocol\"].isin(['Position Skellefteå','-----','---Frigör systemet---','.OL Benlängd 20-40kg belastad','.OL Benlängd belastad','.OL Benvinkel DX 20-40kg belastad',\n",
    "                                                '.OL Benvinkel DX 20-50kg belastad','.OL Benvinkel DX belastad','.OL Benvinkel DX stående','.OL Benvinkel SIN 20-50kg belastad','.OL Benvinkel SIN belastad',\n",
    "                                                '.OL Benvinkel SIN stående','.OL Helrygg frontal AP 0-20kg','.OL Helrygg frontal AP 20-50kg','.OL Helrygg frontal AP vuxen','.OL Helrygg frontal PA 0-20kg',\n",
    "                                                '.OL Helrygg frontal PA 20-50kg','.OL Helrygg frontal PA vuxen','.OL Helrygg sida 0-20kg','.OL Helrygg sida 20-50kg','.OL Helrygg sida stag 20-50kg',\n",
    "                                                '.OL Helrygg sida vuxen','.OL Underben DX frontal belastad','.OL Underben SIN frontal belastad','.OL Underben SIN sida belastad','.OT Helrygg frontal',\n",
    "                                                '.OT Helrygg frontal 20-50kg','.OT Helrygg frontal vuxen','.OT Lårben DX frontal','.OT Lårben SIN frontal','.OT Tunntarmspassage','.OT Underben DX frontal',\n",
    "                                                '.OT Underben DX sida','.OT Underben SIN frontal','.OT Underben SIN sida','CP_Shunt','CP_Vuxen esofagus','CP_antiiso','OL Benvinkel DX stående',\n",
    "                                                'OL Benvinkel SIN stående','OL Helrygg frontal PA vuxen','OL Helrygg sida vuxen','OT Buköversikt','OT Helrygg frontal vuxen','OT Helrygg sida vuxen',\n",
    "                                                'OT Lårben DX frontal','OT Lårben SIN frontal','OT Tunntarm','OT Tunntarmpassage','OT Underben DX frontal','OT Underben DX sida','OT Underben SIN frontal',\n",
    "                                                'OT Underben SIN sida','OW Benlängd belastad','OW Benvinkel DX','OW Benvinkel DX 20-40 kg','OW Benvinkel SIN',\"OW Helrygg frontal 20 -30 kg\", \n",
    "                                                \"OW Helrygg frontal 30-40 kg\", \"OW Helrygg frontal 40-50 kg\", \"OW Helrygg frontal 50-60 kg\", \"OW Helrygg frontal 60-70 kg\", \"OW Helrygg frontal vuxen\", \n",
    "                                                \"OW Helrygg sida 20-30 kg\", \"OW Helrygg sida 30-40 kg\", \"OW Helrygg sida 40-50 kg\", \"OW Helrygg sida 50-60 kg\", \"OW Helrygg sida 60-70 kg\", \n",
    "                                                \"OW Helrygg sida vuxen\", \"OW Skalle-halsrygg-bröstrygg frontal\", \"OW Skalle-halsrygg-bröstrygg sida\",'Sondläge','____________________'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Match and identify nr of duplicate acq.prot for each studyUID, \n",
    "duplicate_acqprot = ft_merged.pivot_table(\n",
    "    index='studyInstanceUID',\n",
    "    values='acquisitionProtocol',\n",
    "    aggfunc=[\n",
    "        lambda x: x.duplicated().sum(),\n",
    "        'count'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "duplicate_acqprot.columns = ['duplicates', 'total_count']\n",
    "\n",
    "# Extract data from DataFrame to \n",
    "duplicates_dup = duplicate_acqprot['duplicates']\n",
    "duplicates_tot = duplicate_acqprot['total_count']\n",
    "duplicates_rat = round(100*(duplicate_acqprot['duplicates'] / duplicate_acqprot['total_count']))\n",
    "duplicates_rat.name = \"Ratio\"\n",
    "\n",
    "# Then perform the merge\n",
    "joined_ft_merged = pd.merge(ft_merged, duplicates_dup, on='studyInstanceUID', how=\"left\")\n",
    "joined_ft_merged = pd.merge(joined_ft_merged, duplicates_tot, on='studyInstanceUID', how=\"left\")\n",
    "joined_ft_merged = pd.merge(joined_ft_merged.reset_index(), duplicates_rat.reset_index(), on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "\n",
    "# Test to identify nr of extra acq.prot due to re-takes\n",
    "duplicate_UID = ft_merged.pivot_table(\n",
    "    index='studyDescription',\n",
    "    values='studyInstanceUID',\n",
    "    aggfunc=[\n",
    "        lambda x: x.duplicated().sum(),\n",
    "        'count'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "duplicate_UID.columns = ['duplicates', 'total_count']\n",
    "\n",
    "# Print for de-bug\n",
    "#print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 33 % of all examinations have one or more retake images\n",
      "About 16 % of all exposures are retakes\n",
      "studyDescription\n",
      ".FOT DX            67.0\n",
      ".HÖFTLED DX        94.0\n",
      ".HÖFTLED SIN        0.0\n",
      ".KNÄLED DX         60.0\n",
      "ANSIKSSKELETT       0.0\n",
      "                   ... \n",
      "Öra cochlea DX      0.0\n",
      "Öra cochlea SIN    40.0\n",
      "Överarm            75.0\n",
      "Överarm DX         63.0\n",
      "Överarm SIN        62.0\n",
      "Name: duplicate_percentage, Length: 99, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Estimate ratios of interest from dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ratio, nr of examinations that include one or more re-takes,\n",
    "P_exam = round(100*(duplicate_acqprot['duplicates'] >0 ).sum()/len(duplicate_acqprot))\n",
    "print(f\"About {P_exam} % of all examinations have one or more retake images\")\n",
    "\n",
    "# Ratio, tot nr of extra exposures due to re-takes,\n",
    "P_expo = round(100*(duplicate_acqprot['duplicates'].sum()/duplicate_acqprot['total_count'].sum()))\n",
    "print(f\"About {P_expo} % of all exposures are retakes\")\n",
    "\n",
    "# Estimate percentage for a acq.prot to require one or more re-takes to complete\n",
    "duplicate_UID['duplicate_percentage'] = round(100*(duplicate_UID['duplicates']/duplicate_UID['total_count']))\n",
    "print(duplicate_UID['duplicate_percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Score\n",
      "0    Alice   25     85\n",
      "1      Bob   30     90\n",
      "2  Charlie   35     95\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Score': [85, 90, 95]\n",
    "})\n",
    "\n",
    "# Extracting a column\n",
    "series1 = df['Age']  # Series with just the 'Age' column\n",
    "\n",
    "# Flattening the entire DataFrame\n",
    "series2 = df.stack()\n",
    "\n",
    "# Extracting a row\n",
    "series3 = df.loc[1]  # Row with index 1 (Bob)\n",
    "\n",
    "# Combining all values\n",
    "series4 = pd.Series(df.values.flatten())\n",
    "\n",
    "print(df)\n",
    "print(series1)\n",
    "#print(series2)\n",
    "#print(series3)\n",
    "#print(series4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
