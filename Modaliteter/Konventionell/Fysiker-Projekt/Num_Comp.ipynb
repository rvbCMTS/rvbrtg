{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Initiate system\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd \n",
    "\n",
    "# Load data as pickle\n",
    "df_Series = pd.read_pickle(\"./Data_24-12-05/series_data.pkl\")\n",
    "df_Study = pd.read_pickle(\"./Data_24-12-05/study_data.pkl\")\n",
    "\n",
    "# Merge data based on studyInstanceUID\n",
    "data = pd.merge(df_Series.reset_index(), df_Study.reset_index(), on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "# Filter merged data, remove all relatively un-wanted acq_prots\n",
    "seperate_acq_prots = ['Position Skellefteå','-----','---Frigör systemet---','.OL Benlängd 20-40kg belastad','.OL Benlängd belastad','.OL Benvinkel DX 20-40kg belastad', '.OL Benvinkel DX 20-50kg belastad',\n",
    "                                                '.OL Benvinkel DX belastad','.OL Benvinkel DX stående','.OL Benvinkel SIN 20-50kg belastad','.OL Benvinkel SIN belastad',\n",
    "                                                '.OL Benvinkel SIN stående','.OL Helrygg frontal AP 0-20kg','.OL Helrygg frontal AP 20-50kg','.OL Helrygg frontal AP vuxen','.OL Helrygg frontal PA 0-20kg',\n",
    "                                                '.OL Helrygg frontal PA 20-50kg','.OL Helrygg frontal PA vuxen','.OL Helrygg sida 0-20kg','.OL Helrygg sida 20-50kg','.OL Helrygg sida stag 20-50kg',\n",
    "                                                '.OL Helrygg sida vuxen','.OL Underben DX frontal belastad','.OL Underben SIN frontal belastad','.OL Underben SIN sida belastad','.OT Helrygg frontal',\n",
    "                                                '.OT Helrygg frontal 20-50kg','.OT Helrygg frontal vuxen','.OT Lårben DX frontal','.OT Lårben SIN frontal','.OT Tunntarmspassage','.OT Underben DX frontal',\n",
    "                                                '.OT Underben DX sida','.OT Underben SIN frontal','.OT Underben SIN sida','CP_Shunt','CP_Vuxen esofagus','CP_antiiso','OL Benvinkel DX stående',\n",
    "                                                'OL Benvinkel SIN stående','OL Helrygg frontal PA vuxen','OL Helrygg sida vuxen','OT Buköversikt','OT Helrygg frontal vuxen','OT Helrygg sida vuxen',\n",
    "                                                'OT Lårben DX frontal','OT Lårben SIN frontal','OT Tunntarm','OT Tunntarmpassage','OT Underben DX frontal','OT Underben DX sida','OT Underben SIN frontal',\n",
    "                                                'OT Underben SIN sida','OW Benlängd belastad','OW Benvinkel DX','OW Benvinkel DX 20-40 kg','OW Benvinkel SIN',\"OW Helrygg frontal 20 -30 kg\", \n",
    "                                                \"OW Helrygg frontal 30-40 kg\", \"OW Helrygg frontal 40-50 kg\", \"OW Helrygg frontal 50-60 kg\", \"OW Helrygg frontal 60-70 kg\", \"OW Helrygg frontal vuxen\", \n",
    "                                                \"OW Helrygg sida 20-30 kg\", \"OW Helrygg sida 30-40 kg\", \"OW Helrygg sida 40-50 kg\", \"OW Helrygg sida 50-60 kg\", \"OW Helrygg sida 60-70 kg\", \n",
    "                                                \"OW Helrygg sida vuxen\", \"OW Skalle-halsrygg-bröstrygg frontal\", \"OW Skalle-halsrygg-bröstrygg sida\",'Sondläge','____________________']\n",
    "filtered_data = data[~data[\"acquisitionProtocol\"].isin(seperate_acq_prots)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Match data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Match and identify duplicate acq_prot per studyInstanceUID, \n",
    "duplicate_acqprot = filtered_data.pivot_table(\n",
    "    index='studyInstanceUID',\n",
    "    values='acquisitionProtocol',\n",
    "    aggfunc=[\n",
    "        lambda x: x.duplicated().sum(),\n",
    "        'count'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rename columns\n",
    "duplicate_acqprot.columns = ['duplicates', 'total_count']\n",
    "\n",
    "# Calc ratio of duplicate examinations per studyInstanceUID, \n",
    "duplicate_acqprot[\"Ratio\"] = round(100*(duplicate_acqprot['duplicates'] / duplicate_acqprot['total_count']))\n",
    "\n",
    "# Add duplicate acq_prot per studyInstanceUID to main DataFrame\n",
    "joined_data = pd.merge(filtered_data, duplicate_acqprot, on='studyInstanceUID', how=\"left\")\n",
    "\n",
    "# Remove studyInstanceUID duplicates to avoid double counting total_count when calc certain ratio\n",
    "limited_data = joined_data.drop_duplicates(\"studyInstanceUID\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About 33 % of all examinations have one or more retake images\n",
      "About 16 % of all exposures are retakes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Estimate ratios of interest from dataset\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ratio, examinations that include one or more re-takes,\n",
    "P_exam = round(100*(duplicate_acqprot['duplicates'] >0 ).sum()/len(duplicate_acqprot))\n",
    "print(f\"About {P_exam} % of all examinations have one or more retake images\")\n",
    "\n",
    "# Ratio, tot exposures due to re-takes,\n",
    "P_expo = round(100*(duplicate_acqprot['duplicates'].sum()/duplicate_acqprot['total_count'].sum()))\n",
    "print(f\"About {P_expo} % of all exposures are retakes\")\n",
    "\n",
    "# Ratio, Retakes per studyDescription\n",
    "duplicate_studies = limited_data.groupby('studyDescription').agg(\n",
    "    duplicate_count = (\"duplicates\", \"sum\",),\n",
    "    study_expo_count = (\"total_count\", \"sum\"))\n",
    "duplicate_studies[\"ratio\"] = round(100*(duplicate_studies.duplicate_count / duplicate_studies.study_expo_count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
